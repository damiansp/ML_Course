{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO Regression (coordinate descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize weights for Lasso regression (OLS + L1 penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create is assigned to damiansp@gmail.com and will expire on March 07, 2017. For commercial licensing options, visit https://dato.com/buy/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-05-27 19:28:50,206 [INFO] graphlab.cython.cy_server, 176: GraphLab Create v1.9 started. Logging: /tmp/graphlab_server_1464391728.log\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')\n",
    "sales['floors'] = sales['floors'].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy useful functions from previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 \n",
    "    features = ['constant'] + features \n",
    "    features_sframe = data_sframe[features]\n",
    "    print features_sframe.head()\n",
    "\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    output_sarray = data_sframe[output]\n",
    "\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    \n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize features\n",
    "As with many ML algorithms, Lasso regression works best when features are normalized to all be on comparable scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short function that normalizes columns of a given feature matrix. It also returns a pair `(normalized_features, norms)`, where the second item contains the norms of original features. This will be used to repeat identical transformation of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis = 0)\n",
    "    normalized_features = feature_matrix / norms\n",
    "    return (normalized_features, norms)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6  0.6  0.6]\n",
      " [ 0.8  0.8  0.8]]\n",
      "[  5.  10.  15.]\n"
     ]
    }
   ],
   "source": [
    "features, norms = normalize_features(np.array([[3.,6.,9.],[4.,8.,12.]]))\n",
    "print features\n",
    "print norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Coordinate Descent with normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seek to obtain a sparse set of weights by minimizing the LASSO cost function (RSS + L1_penalty)\n",
    "```\n",
    "SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|).\n",
    "```\n",
    "(By convention, do not include `w[0]` in the L1 penalty term so as not to zero the intercept term.)\n",
    "\n",
    "The absolute value sign makes the cost function non-differentiable, so gradient descent is not viable as it was for OLS or ridge regression.  Instead, this algorithm uses **coordinate descent**: at each iteration, we will fix all weights but weight `i` and find the value of weight `i` that minimizes the objective. That is:\n",
    "```\n",
    "argmin_{w[i]} [ SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|) ]\n",
    "```\n",
    "where all weights other than `w[i]` are held to be constant. \n",
    "Optimize one `w[i]` at a time, circling through the weights multiple times.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here **cyclical coordinate descent with normalized features** is used, where coordinates 0 to (d-1) are cycled through in order, and assumes the features were normalized as discussed above. The formula for optimizing each coordinate is as follows:\n",
    "```\n",
    "       ┌ (rho[i] + lambd a /2)     if rho[i] < -lambda / 2\n",
    "w[i] = ├ 0                         if - lambda / 2 <= ro[i] <= lambda / 2\n",
    "       └ (rho[i] - lambda / 2)     if rho[i] > lambda / 2\n",
    "```\n",
    "where\n",
    "```\n",
    "rho[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ].\n",
    "```\n",
    "\n",
    "Do not regularize the intercept `w[0]`. It is updated as:\n",
    "```\n",
    "w[0] = rho[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a simple model with 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+\n",
      "| constant | sqft_living | bedrooms |\n",
      "+----------+-------------+----------+\n",
      "|    1     |    1180.0   |   3.0    |\n",
      "|    1     |    2570.0   |   3.0    |\n",
      "|    1     |    770.0    |   2.0    |\n",
      "|    1     |    1960.0   |   4.0    |\n",
      "|    1     |    1680.0   |   3.0    |\n",
      "|    1     |    5420.0   |   4.0    |\n",
      "|    1     |    1715.0   |   3.0    |\n",
      "|    1     |    1060.0   |   3.0    |\n",
      "|    1     |    1780.0   |   3.0    |\n",
      "|    1     |    1890.0   |   3.0    |\n",
      "+----------+-------------+----------+\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00680209  0.00353021  0.00583571]\n",
      " [ 0.00680209  0.00768869  0.00583571]\n",
      " [ 0.00680209  0.00230361  0.00389048]\n",
      " ..., \n",
      " [ 0.00680209  0.00305154  0.00389048]\n",
      " [ 0.00680209  0.00478673  0.00583571]\n",
      " [ 0.00680209  0.00305154  0.00389048]]\n"
     ]
    }
   ],
   "source": [
    "simple_feature_matrix, norms = normalize_features(simple_feature_matrix)\n",
    "print simple_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign some random set of initial weights and inspect the values of `rho[i]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = np.array([1., 4., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `predict_output()` to make predictions on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02675867,  0.04339256,  0.01990703, ...,  0.02289873,\n",
       "        0.03178473,  0.02289873])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict_output(simple_feature_matrix, weights)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the values of `rho[i]` for each feature in this simple model, using the formula given above, using the formula:\n",
    "```\n",
    "rho[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rho = []\n",
    "\n",
    "for i in xrange(3):\n",
    "    feature_i = simple_feature_matrix[:, i] # 1 x n\n",
    "    rho.append(sum(feature_i * (output - prediction + weights[i] * feature_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-175878941.54598159, 175878941.54598159)\n",
      "(-161933397.3519305, 161933397.3519305)\n"
     ]
    }
   ],
   "source": [
    "rho1_zeros = (-2 * rho[1], 2 * rho[1])\n",
    "rho2_zeros = (-2 * rho[2], 2 * rho[2])\n",
    "print rho1_zeros\n",
    "print rho2_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `rho[i]` quantifies the significance of the ith feature; the larger `rho[i]` is, the more likely it is for the ith feature to be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Coordinate Descent Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the formula above, coordinate descent that minimizes the cost function over a single feature i is implemented. (Note that the intercept (weight 0) is not regularized.) Return updated weight for feature i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    prediction = predict_output(feature_matrix, weights) # (2,)\n",
    "    \n",
    "    # compute rho[i] = SUM[ [feature_i]*(output - prediction + weight[i]*[feature_i]) ]\n",
    "    feature_i = feature_matrix[:, i] \n",
    "    rho_i = sum(feature_i * (output - prediction + weights[i] * feature_i))\n",
    "\n",
    "    if i == 0: # intercept -- do not regularize\n",
    "        new_weight_i = rho_i \n",
    "    elif rho_i < -l1_penalty / 2.:\n",
    "        new_weight_i = rho_i + l1_penalty / 2\n",
    "    elif rho_i > l1_penalty/2.:\n",
    "        new_weight_i = rho_i - l1_penalty / 2\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425558846691\n"
     ]
    }
   ],
   "source": [
    "print lasso_coordinate_descent_step(\n",
    "    i = 1, \n",
    "    feature_matrix = np.array([[3. / np.sqrt(13), 1./ np.sqrt(10)], [2. / np.sqrt(13), 3./ np.sqrt(10)]]),\n",
    "    output = np.array([1., 1.]),\n",
    "    weights = np.array([1., 4.]), \n",
    "    l1_penalty = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cyclical coordinate descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that optimizes the cost function over a single coordinate, implement cyclical coordinate descent to optimize coordinates 0, 1, ..., (d-1) in order and repeat.\n",
    "\n",
    "When to stop? \n",
    "\n",
    "Each time we scan all the coordinates (features) once, we measure the change in weight for each coordinate. If no coordinate changes by more than a specified threshold, stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    max_step = 1e10\n",
    "    weights = initial_weights\n",
    "    \n",
    "    while max_step > tolerance:\n",
    "        max_step = 0\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            old_weight = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            \n",
    "            coord_change = abs(weights[i] - old_weight)\n",
    "            if coord_change > max_step:\n",
    "                max_step = coord_change\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized version of the feature matrix, `normalized_simple_feature_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+\n",
      "| constant | sqft_living | bedrooms |\n",
      "+----------+-------------+----------+\n",
      "|    1     |    1180.0   |   3.0    |\n",
      "|    1     |    2570.0   |   3.0    |\n",
      "|    1     |    770.0    |   2.0    |\n",
      "|    1     |    1960.0   |   4.0    |\n",
      "|    1     |    1680.0   |   3.0    |\n",
      "|    1     |    5420.0   |   4.0    |\n",
      "|    1     |    1715.0   |   3.0    |\n",
      "|    1     |    1060.0   |   3.0    |\n",
      "|    1     |    1780.0   |   3.0    |\n",
      "|    1     |    1890.0   |   3.0    |\n",
      "+----------+-------------+----------+\n",
      "[10 rows x 3 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(simple_feature_matrix, output) = get_numpy_data(sales, simple_features, my_output)\n",
    "(normalized_simple_feature_matrix, simple_norms) = normalize_features(simple_feature_matrix) # normalize features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run LASSO coordinate descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = lasso_cyclical_coordinate_descent(\n",
    "    normalized_simple_feature_matrix, output, initial_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [ 21624998.36636353  63157246.78545319         0.        ]\n",
      "rss: 1.63049248148e+15\n"
     ]
    }
   ],
   "source": [
    "print 'weights:', weights\n",
    "preds = predict_output(normalized_simple_feature_matrix, weights)\n",
    "error = preds - output\n",
    "print 'rss:', sum(error ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LASSO fit with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the sales dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = sales.random_split(0.8, seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized feature matrix from the TRAINING data with these features.  (Store the norms for the normalization, to be used again on the TEST data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-------------+----------+--------+------------+\n",
      "| constant | bedrooms | bathrooms | sqft_living | sqft_lot | floors | waterfront |\n",
      "+----------+----------+-----------+-------------+----------+--------+------------+\n",
      "|    1     |   3.0    |    1.0    |    1180.0   |   5650   |   1    |     0      |\n",
      "|    1     |   3.0    |    2.25   |    2570.0   |   7242   |   2    |     0      |\n",
      "|    1     |   2.0    |    1.0    |    770.0    |  10000   |   1    |     0      |\n",
      "|    1     |   4.0    |    3.0    |    1960.0   |   5000   |   1    |     0      |\n",
      "|    1     |   3.0    |    2.0    |    1680.0   |   8080   |   1    |     0      |\n",
      "|    1     |   4.0    |    4.5    |    5420.0   |  101930  |   1    |     0      |\n",
      "|    1     |   3.0    |    2.25   |    1715.0   |   6819   |   2    |     0      |\n",
      "|    1     |   3.0    |    1.5    |    1060.0   |   9711   |   1    |     0      |\n",
      "|    1     |   3.0    |    1.0    |    1780.0   |   7470   |   1    |     0      |\n",
      "|    1     |   3.0    |    2.5    |    1890.0   |   6560   |   2    |     0      |\n",
      "+----------+----------+-----------+-------------+----------+--------+------------+\n",
      "+------+-----------+-------+------------+---------------+----------+--------------+\n",
      "| view | condition | grade | sqft_above | sqft_basement | yr_built | yr_renovated |\n",
      "+------+-----------+-------+------------+---------------+----------+--------------+\n",
      "|  0   |     3     |   7   |    1180    |       0       |   1955   |      0       |\n",
      "|  0   |     3     |   7   |    2170    |      400      |   1951   |     1991     |\n",
      "|  0   |     3     |   6   |    770     |       0       |   1933   |      0       |\n",
      "|  0   |     5     |   7   |    1050    |      910      |   1965   |      0       |\n",
      "|  0   |     3     |   8   |    1680    |       0       |   1987   |      0       |\n",
      "|  0   |     3     |   11  |    3890    |      1530     |   2001   |      0       |\n",
      "|  0   |     3     |   7   |    1715    |       0       |   1995   |      0       |\n",
      "|  0   |     3     |   7   |    1060    |       0       |   1963   |      0       |\n",
      "|  0   |     3     |   7   |    1050    |      730      |   1960   |      0       |\n",
      "|  0   |     3     |   7   |    1890    |       0       |   2003   |      0       |\n",
      "+------+-----------+-------+------------+---------------+----------+--------------+\n",
      "[10 rows x 14 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(training_feature_matrix, output) = get_numpy_data(train_data, all_features, 'price')\n",
    "train_normalized, train_norms = normalize_features(training_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the weights with `l1_penalty = 1e7`, on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_weights = np.zeros(len(all_features) + 1)\n",
    "tolerance = 1.0\n",
    "#includes w[0], (intercept)\n",
    "feat = ['intercept'] + all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24429600.60933346         0.                 0.          48389174.35227959\n",
      "         0.                 0.           3317511.16271979\n",
      "   7329961.98489638         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights1e7 = lasso_cyclical_coordinate_descent(\n",
    "    train_normalized, output, init_weights, 1e7, tolerance)\n",
    "print weights1e7\n",
    "\n",
    "#for (f, w) in zip(feat, weights1e7):\n",
    "#    print (f, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the weights were optimized for the *normalized* feature matrix, to use these weights on a test set, we must normalize the test data in the same way.\n",
    "\n",
    "Alternatively, we can rescale the learned weights to include the normalization, so we never have to worry about normalizing the test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized version of each of the weights learned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24429600.60933346         0.                 0.          48389174.35227959\n",
      "         0.                 0.           3317511.16271979\n",
      "   7329961.98489638         0.                 0.                 0.\n",
      "         0.                 0.                 0.        ]\n",
      "[  1.85285533e+05   0.00000000e+00   0.00000000e+00   1.61317456e+02\n",
      "   0.00000000e+00   0.00000000e+00   2.87664700e+05   6.91937057e+04\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "weights1e7_normalized = weights1e7 / train_norms\n",
    "print weights1e7\n",
    "print weights1e7_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, learn the weights with `l1_penalty = 1e8`, on the training data, then rescale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71114625.75280942         0.                 0.                 0.\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.                 0.                 0.\n",
      "         0.                 0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights1e8 = lasso_cyclical_coordinate_descent(\n",
    "    train_normalized, output, init_weights, 1e8, tolerance)\n",
    "print weights1e8\n",
    "#for (f, w) in zip(feat, weights1e8):\n",
    "#    print (f, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 539366.62822135       0.               0.               0.               0.\n",
      "       0.               0.               0.               0.               0.\n",
      "       0.               0.               0.               0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights1e8_normalized = weights1e8 / train_norms\n",
    "print weights1e8_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, learn the weights with `l1_penalty = 1e4`, on the training data, and rescale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77779073.91265044 -22884012.25023264  15348487.08089934\n",
      "  92166869.69883147  -2139328.08242773  -8818455.54409455\n",
      "   6494209.73310656   7065162.05053201   4119079.21006769\n",
      "  18436483.52618784 -14566678.54514407  -5528348.7517945  -83591746.20730424\n",
      "   2784276.46012856]\n"
     ]
    }
   ],
   "source": [
    "weights1e4 = lasso_cyclical_coordinate_descent(\n",
    "    train_normalized, output, init_weights, 1e4, 5e5)\n",
    "print weights1e4\n",
    "#for (f, w) in zip(feat, weights1e4):\n",
    "#    print (f, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77779073.91265044 -22884012.25023264  15348487.08089934\n",
      "  92166869.69883147  -2139328.08242773  -8818455.54409455\n",
      "   6494209.73310656   7065162.05053201   4119079.21006769\n",
      "  18436483.52618784 -14566678.54514407  -5528348.7517945  -83591746.20730424\n",
      "   2784276.46012856]\n",
      "[  5.89912924e+05  -4.97435039e+04   5.17044250e+04   3.07261390e+02\n",
      "  -3.67765574e-01  -4.32048893e+04   5.63119400e+05   6.66940353e+04\n",
      "   8.99767715e+03   1.80569342e+04  -5.60846894e+01  -7.88384489e+01\n",
      "  -3.21603081e+02   5.18531810e+01]\n"
     ]
    }
   ],
   "source": [
    "weights1e4_normalized = weights1e4 / train_norms\n",
    "print weights1e4\n",
    "print weights1e4_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating each of the learned models on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the three models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-------------+----------+--------+------------+\n",
      "| constant | bedrooms | bathrooms | sqft_living | sqft_lot | floors | waterfront |\n",
      "+----------+----------+-----------+-------------+----------+--------+------------+\n",
      "|    1     |   3.0    |    1.0    |    1430.0   |  19901   |   1    |     0      |\n",
      "|    1     |   4.0    |    3.0    |    2950.0   |   5000   |   2    |     0      |\n",
      "|    1     |   3.0    |    2.0    |    1710.0   |   4697   |   1    |     0      |\n",
      "|    1     |   3.0    |    2.5    |    2320.0   |   3980   |   2    |     0      |\n",
      "|    1     |   3.0    |    1.0    |    1090.0   |   3000   |   1    |     0      |\n",
      "|    1     |   4.0    |    2.5    |    2620.0   |   7553   |   2    |     0      |\n",
      "|    1     |   4.0    |    2.25   |    4220.0   |  24186   |   1    |     0      |\n",
      "|    1     |   4.0    |    2.5    |    2250.0   |   4495   |   2    |     0      |\n",
      "|    1     |   3.0    |    1.75   |    1260.0   |   8400   |   1    |     0      |\n",
      "|    1     |   4.0    |    2.0    |    2750.0   |   7807   |   1    |     0      |\n",
      "+----------+----------+-----------+-------------+----------+--------+------------+\n",
      "+------+-----------+-------+------------+---------------+----------+--------------+\n",
      "| view | condition | grade | sqft_above | sqft_basement | yr_built | yr_renovated |\n",
      "+------+-----------+-------+------------+---------------+----------+--------------+\n",
      "|  0   |     4     |   7   |    1430    |       0       |   1927   |      0       |\n",
      "|  3   |     3     |   9   |    1980    |      970      |   1979   |      0       |\n",
      "|  0   |     5     |   6   |    1710    |       0       |   1941   |      0       |\n",
      "|  0   |     3     |   8   |    2320    |       0       |   2003   |      0       |\n",
      "|  0   |     4     |   8   |    1090    |       0       |   1929   |      0       |\n",
      "|  0   |     3     |   8   |    2620    |       0       |   1996   |      0       |\n",
      "|  0   |     3     |   8   |    2600    |      1620     |   1984   |      0       |\n",
      "|  0   |     3     |   7   |    2250    |       0       |   2008   |      0       |\n",
      "|  0   |     3     |   7   |    1260    |       0       |   1954   |      0       |\n",
      "|  0   |     5     |   7   |    2250    |      500      |   1916   |      0       |\n",
      "+------+-----------+-------+------------+---------------+----------+--------------+\n",
      "[10 rows x 14 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, all_features, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS of each of the three normalized weights on the (unnormalized) `test_feature_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rss: 2.2778100476e+14\n"
     ]
    }
   ],
   "source": [
    "preds1e4 = predict_output(test_feature_matrix, weights1e4_normalized)\n",
    "error = preds1e4 - test_output\n",
    "rss1e4 = sum(error ** 2)\n",
    "print 'rss:', rss1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rss: 2.75962079909e+14\n"
     ]
    }
   ],
   "source": [
    "preds1e7 = predict_output(test_feature_matrix, weights1e7_normalized)\n",
    "error = preds1e7 - test_output\n",
    "rss1e7 = sum(error ** 2)\n",
    "print 'rss:', rss1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rss: 5.37166150034e+14\n"
     ]
    }
   ],
   "source": [
    "preds1e8 = predict_output(test_feature_matrix, weights1e8_normalized)\n",
    "error = preds1e8 - test_output\n",
    "rss1e8 = sum(error ** 2)\n",
    "print 'rss:', rss1e8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
